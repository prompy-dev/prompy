# Model Fine-Tuning

This directory contains all the resources needed for fine-tuning language models for the prompt engineering feedback system.

## Directory Structure

- `/data`: Training and validation datasets in JSONL format
- `/scripts`: Python scripts for data preparation, training, and evaluation
- `/config`: Configuration files for fine-tuning parameters
- `/models`: Directory to store model checkpoints (gitignored)

## Environment Setup

The scripts require the following environment variables:

- `OPENAI_API_KEY`: Your OpenAI API key (required)
- `OPENAI_ORG_ID`: Your OpenAI organization ID (optional)

If you belong to multiple OpenAI organizations, setting the organization ID ensures your fine-tuning job is associated with the correct organization. If not provided, the default organization linked to your API key will be used.

## Model Naming

When fine-tuning completes, OpenAI will create a model with a name following this pattern:

```
ft:gpt-3.5-turbo-0613:organization:custom-suffix:random-id
```

Where:

- `ft:` indicates it's a fine-tuned model
- `gpt-3.5-turbo-0613` is the base model and version from your config
- `organization` is your OpenAI organization ID
- `custom-suffix` is your optional suffix (specified in config)
- `random-id` is a unique identifier generated by OpenAI

You can customize the name by setting the `suffix` parameter in the `hyperparameters.yaml` file.

## Automated Model Deployment

We've automated the entire process of fine-tuning and deploying models with the `deploy_model.py` script.

### One-Command Deployment

```bash
# Run from the scripts directory
cd scripts
python deploy_model.py --input ../data/your_dataset.jsonl --model-type parse_query
```

This single command will:

1. Process and validate your training data
2. Submit the fine-tuning job to OpenAI
3. Monitor the job until completion
4. Extract the new model ID
5. Update environment variables to use the new model
6. Register the model in a central registry for tracking

### Command Options

```bash
python deploy_model.py --help
```

Key options:

- `--input`: Path to your training data file
- `--model-type`: Which component will use this model (parse_query, chat_llm, or custom)
- `--skip-training`: Deploy an existing model without running fine-tuning
- `--model-id`: Specify an existing model ID when using --skip-training
- `--env-file`: Path to the .env file to update (default: .env in project root)

### Environment Variable Management

The script automatically updates an `.env` file with the appropriate environment variable:

- For `parse_query` models: `PARSE_QUERY_MODEL_ID=your-model-id`
- For `chat_llm` models: `OPENAI_MODEL_ID=your-model-id`
- For custom types: `CUSTOM_TYPE_MODEL_ID=your-model-id`

Your application should load this .env file on startup:

```python
# Add to your main application file
from dotenv import load_dotenv
load_dotenv()  # This loads .env variables into os.environ
```

### Model Registry

The script maintains a registry of all fine-tuned models at `fine-tuning/models/registry.json`. This registry tracks:

- Model IDs
- Deployment dates
- Model types
- Base models
- Job IDs

This provides a history of all your fine-tuned models for reference and rollback if needed.

## Training Data Format

Different components require specific formats for their training data:

### Parse Query Component

For training a model to parse user queries:

```json
{
  "messages": [
    {
      "role": "system",
      "content": "You will return a JSON object with attributes like task, role, context, etc."
    },
    {
      "role": "user",
      "content": "Write a prompt for a story about space exploration"
    },
    {
      "role": "assistant",
      "content": "{\"user_query\": \"Write a prompt for a story about space exploration\", \"task\": true, \"role\": false, \"context\": false, \"rules\": false, \"examples\": false, \"format\": false}"
    }
  ]
}
```

### Feedback Generation Component

For training a model to provide prompt engineering feedback:

```json
{
  "messages": [
    {
      "role": "system",
      "content": "You are an AI assistant that provides helpful, accurate, and concise feedback on prompt engineering."
    },
    {
      "role": "user",
      "content": "Create a prompt to get GPT to generate a poem about cats."
    },
    {
      "role": "assistant",
      "content": "Your prompt lacks specific guidance and constraints. Consider adding: 1) Desired style/tone, 2) Length requirements, 3) Specific themes beyond 'cats', 4) Structure (sonnet, haiku, etc). Example improvement: 'Write a 12-line poem about cats' hunting behavior at night. Use a mysterious tone with vivid imagery and include a metaphor comparing cats to shadows.'"
    }
  ]
}
```

## Manual Workflow (Alternative to Automation)

If you prefer to run each step manually:

1. **Prepare data**:

   ```bash
   python scripts/prepare_data.py --input data/your_dataset.jsonl
   ```

2. **Start fine-tuning**:

   ```bash
   python scripts/train.py
   ```

3. **Monitor progress**:

   ```bash
   python scripts/monitor_job.py --job-id your_job_id --continuous
   ```

4. **Set environment variable manually**:
   ```bash
   export PARSE_QUERY_MODEL_ID="ft:gpt-3.5-turbo-0613:your-model-id"
   ```
